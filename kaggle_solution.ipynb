{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad69f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from colorama import Fore, Style, init\n",
    "from scipy.optimize import minimize\n",
    "import warnings\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5123f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "init(autoreset=True)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    xgb_device = 'cuda'\n",
    "else:\n",
    "    xgb_device = 'cpu'\n",
    "\n",
    "print(\"XGBoost device:\", xgb_device)\n",
    "\n",
    "SEED = 42\n",
    "FOLDS = 7\n",
    "ALPHA = 0.1\n",
    "MIN_COVERAGE = 0.90\n",
    "\n",
    "print(\"Enhanced Two-Stage Uncertainty Model\")\n",
    "print(\"Minimum Coverage:\", MIN_COVERAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5ad5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def winkler_score(y_true, lower, upper, alpha=0.1, return_coverage=False):\n",
    "\n",
    "    y_true = np.asarray(y_true)\n",
    "    lower = np.asarray(lower)\n",
    "    upper = np.asarray(upper)\n",
    "\n",
    "    width = upper - lower\n",
    "\n",
    "    penalty_lower = 2 / alpha * (lower - y_true)\n",
    "    penalty_upper = 2 / alpha * (y_true - upper)\n",
    "\n",
    "    score = width \\\n",
    "        + np.where(y_true < lower, penalty_lower, 0) \\\n",
    "        + np.where(y_true > upper, penalty_upper, 0)\n",
    "\n",
    "    if return_coverage:\n",
    "        coverage = np.mean((y_true >= lower) & (y_true <= upper))\n",
    "        return np.mean(score), coverage\n",
    "\n",
    "    return np.mean(score)\n",
    "\n",
    "\n",
    "def robust_winkler_objective(gammas, y_true, y_hat, err_hat,\n",
    "                             min_coverage=0.90,\n",
    "                             coverage_penalty=1000000):\n",
    "\n",
    "    gamma0 = gammas[0]\n",
    "    gamma1 = gammas[1]\n",
    "\n",
    "    err_term = np.sqrt(err_hat)\n",
    "\n",
    "    lower = y_hat - gamma0 * err_term\n",
    "    upper = y_hat + gamma1 * err_term\n",
    "\n",
    "    score, coverage = winkler_score(\n",
    "        y_true, lower, upper, return_coverage=True\n",
    "    )\n",
    "\n",
    "    if coverage < min_coverage:\n",
    "        penalty = coverage_penalty * (min_coverage - coverage) ** 2\n",
    "        score = score + penalty\n",
    "\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f676c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_date(data):\n",
    "\n",
    "    df = data.copy()\n",
    "\n",
    "    df[\"sale_date\"] = pd.to_datetime(df[\"sale_date\"], errors='coerce')\n",
    "\n",
    "    df[\"year\"] = df[\"sale_date\"].dt.year\n",
    "    df[\"month\"] = df[\"sale_date\"].dt.month\n",
    "    df[\"quarter\"] = df[\"sale_date\"].dt.quarter\n",
    "    df[\"day\"] = df[\"sale_date\"].dt.day\n",
    "    df[\"dayofweek\"] = df[\"sale_date\"].dt.dayofweek\n",
    "\n",
    "    df[\"is_weekend\"] = df[\"dayofweek\"].isin([5, 6]).astype(int)\n",
    "    df[\"week_of_year\"] = df[\"sale_date\"].dt.isocalendar().week\n",
    "\n",
    "    df[\"month_sin\"] = np.sin(2 * np.pi * df[\"month\"] / 12)\n",
    "    df[\"month_cos\"] = np.cos(2 * np.pi * df[\"month\"] / 12)\n",
    "\n",
    "    df[\"day_sin\"] = np.sin(2 * np.pi * df[\"day\"] / 31)\n",
    "    df[\"day_cos\"] = np.cos(2 * np.pi * df[\"day\"] / 31)\n",
    "\n",
    "    df[\"week_sin\"] = np.sin(2 * np.pi * df[\"week_of_year\"] / 52)\n",
    "    df[\"week_cos\"] = np.cos(2 * np.pi * df[\"week_of_year\"] / 52)\n",
    "\n",
    "    df[\"is_start_of_month\"] = (df[\"day\"] <= 7).astype(int)\n",
    "    df[\"is_end_of_month\"] = (df[\"day\"] >= 24).astype(int)\n",
    "\n",
    "    df[\"imp_to_land_ratio\"] = df[\"imp_val\"] / (df[\"land_val\"] + 1)\n",
    "    df[\"total_val\"] = df[\"imp_val\"] + df[\"land_val\"]\n",
    "\n",
    "    df[\"val_per_sqft\"] = df[\"total_val\"] / (df[\"sqft\"].replace(0, np.nan) + 1)\n",
    "\n",
    "    df[\"lot_to_building_ratio\"] = df[\"sqft_lot\"] / (df[\"sqft\"] + 1)\n",
    "\n",
    "    df[\"log_total_val\"] = np.log1p(df[\"total_val\"])\n",
    "    df[\"log_sqft\"] = np.log1p(df[\"sqft\"])\n",
    "\n",
    "    if \"year_built\" in df.columns:\n",
    "        df[\"property_age\"] = df[\"year\"] - df[\"year_built\"]\n",
    "\n",
    "    df.drop([\"sale_date\"], axis=1, inplace=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce0982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_neighbours(model, X, y, k, exclude_self):\n",
    "\n",
    "    if exclude_self:\n",
    "        distances, indices = model.kneighbors(X, n_neighbors=k+1)\n",
    "    else:\n",
    "        distances, indices = model.kneighbors(X, n_neighbors=k)\n",
    "\n",
    "    preds = []\n",
    "    dists = []\n",
    "    stds = []\n",
    "\n",
    "    for d, idxs in zip(distances, indices):\n",
    "\n",
    "        if exclude_self:\n",
    "            d = d[1:]\n",
    "            idxs = idxs[1:]\n",
    "\n",
    "        vals = y[idxs]\n",
    "\n",
    "        preds.append(np.mean(vals))\n",
    "        dists.append(np.mean(d))\n",
    "\n",
    "        if len(vals) > 1:\n",
    "            stds.append(np.std(vals))\n",
    "        else:\n",
    "            stds.append(0)\n",
    "\n",
    "    return np.array(preds), np.array(dists), np.array(stds)\n",
    "\n",
    "\n",
    "def preprocess_knn_features(X_tr, X_va, y_tr, knn_features, knn_params):\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    X_tr_knn = scaler.fit_transform(X_tr[knn_features])\n",
    "    X_va_knn = scaler.transform(X_va[knn_features])\n",
    "\n",
    "    X_tr_out = X_tr.copy()\n",
    "    X_va_out = X_va.copy()\n",
    "\n",
    "    for k in [5, 10, 15]:\n",
    "\n",
    "        params = knn_params.copy()\n",
    "        params[\"n_neighbors\"] = k\n",
    "\n",
    "        knn = KNeighborsRegressor(**params)\n",
    "        knn.fit(X_tr_knn, y_tr)\n",
    "\n",
    "        p_tr, d_tr, s_tr = retrieve_neighbours(knn, X_tr_knn, y_tr, k, True)\n",
    "        p_va, d_va, s_va = retrieve_neighbours(knn, X_va_knn, y_tr, k, False)\n",
    "\n",
    "        X_tr_out[\"price_knn_\" + str(k)] = p_tr\n",
    "        X_tr_out[\"dist_knn_\" + str(k)] = d_tr\n",
    "        X_tr_out[\"std_knn_\" + str(k)] = s_tr\n",
    "\n",
    "        X_va_out[\"price_knn_\" + str(k)] = p_va\n",
    "        X_va_out[\"dist_knn_\" + str(k)] = d_va\n",
    "        X_va_out[\"std_knn_\" + str(k)] = s_va\n",
    "\n",
    "    return X_tr_out, X_va_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2c0a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_two_stage_model(X, y, model0, model1, n_splits, seed):\n",
    "\n",
    "    y = np.asarray(y)\n",
    "    oof = np.zeros(len(y))\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    for tr_idx, va_idx in kf.split(X):\n",
    "\n",
    "        X_tr = X.iloc[tr_idx]\n",
    "        X_va = X.iloc[va_idx]\n",
    "        y_tr = y[tr_idx]\n",
    "        y_va = y[va_idx]\n",
    "\n",
    "        model0.fit(X_tr, y_tr)\n",
    "        oof[va_idx] = model0.predict(X_va)\n",
    "\n",
    "    resid_target = (y - oof) ** 2 + 1e-6\n",
    "\n",
    "    X_resid = X.copy()\n",
    "    X_resid[\"y_pred\"] = oof\n",
    "    X_resid[\"y_pred_sq\"] = oof ** 2\n",
    "\n",
    "    model1.fit(X_resid, resid_target)\n",
    "\n",
    "    model0.fit(X, y)\n",
    "\n",
    "    return model0, model1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9127298b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_components(X, model0, model1, lower_bound):\n",
    "\n",
    "    y_hat = model0.predict(X)\n",
    "\n",
    "    X_resid = X.copy()\n",
    "    X_resid[\"y_pred\"] = y_hat\n",
    "    X_resid[\"y_pred_sq\"] = y_hat ** 2\n",
    "\n",
    "    err_hat = model1.predict(X_resid)\n",
    "\n",
    "    err_hat = np.maximum(err_hat, lower_bound)\n",
    "\n",
    "    return y_hat, err_hat\n",
    "\n",
    "\n",
    "def build_intervals(y_hat, err_hat, g0, g1):\n",
    "\n",
    "    err_term = np.sqrt(err_hat)\n",
    "\n",
    "    lower = y_hat - g0 * err_term\n",
    "    upper = y_hat + g1 * err_term\n",
    "\n",
    "    return lower, upper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d977a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"dataset.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "train = preprocess_date(train)\n",
    "test = preprocess_date(test)\n",
    "\n",
    "cat_cols = []\n",
    "for c in train.columns:\n",
    "    if train[c].dtype == \"object\" and c != \"sale_price\":\n",
    "        cat_cols.append(c)\n",
    "\n",
    "encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "\n",
    "train[cat_cols] = encoder.fit_transform(train[cat_cols]).astype(int)\n",
    "test[cat_cols] = encoder.transform(test[cat_cols]).astype(int)\n",
    "\n",
    "print(\"Train shape:\", train.shape)\n",
    "print(\"Test shape:\", test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bde094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_params = {\"weights\": \"distance\"}\n",
    "\n",
    "y = train[\"sale_price\"]\n",
    "\n",
    "scores = []\n",
    "coverages = []\n",
    "\n",
    "kf = KFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(kf.split(train), 1):\n",
    "\n",
    "    print(\"Fold\", fold)\n",
    "\n",
    "    X_tr = train.iloc[tr_idx]\n",
    "    X_va = train.iloc[va_idx]\n",
    "\n",
    "    y_tr = y.iloc[tr_idx]\n",
    "    y_va = y.iloc[va_idx]\n",
    "\n",
    "    X_tr, X_va = preprocess_knn_features(\n",
    "        X_tr, X_va, y_tr,\n",
    "        [\"latitude\", \"longitude\", \"year\"],\n",
    "        knn_params\n",
    "    )\n",
    "\n",
    "    model0 = XGBRegressor(device=xgb_device)\n",
    "    model1 = XGBRegressor(objective=\"reg:gamma\", device=xgb_device)\n",
    "\n",
    "    model0, model1 = fit_two_stage_model(\n",
    "        X_tr, y_tr, model0, model1, FOLDS, SEED\n",
    "    )\n",
    "\n",
    "    y_hat, err_hat = predict_components(X_va, model0, model1, 1000)\n",
    "\n",
    "    lower, upper = build_intervals(y_hat, err_hat, 1.5, 1.6)\n",
    "\n",
    "    score, cov = winkler_score(y_va, lower, upper, return_coverage=True)\n",
    "\n",
    "    print(\"Winkler:\", round(score), \"Coverage:\", round(cov, 4))\n",
    "\n",
    "    scores.append(score)\n",
    "    coverages.append(cov)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4528c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimizing gammas\")\n",
    "\n",
    "best_score = 1e18\n",
    "best_g0 = 1.5\n",
    "best_g1 = 1.6\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    g0 = np.random.uniform(1.2, 2.0)\n",
    "    g1 = np.random.uniform(1.2, 2.0)\n",
    "\n",
    "    score = robust_winkler_objective(\n",
    "        [g0, g1], y_va, y_hat, err_hat, MIN_COVERAGE\n",
    "    )\n",
    "\n",
    "    print(\"Try\", i+1, \"g0\", g0, \"g1\", g1, \"score\", round(score))\n",
    "\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "        best_g0 = g0\n",
    "        best_g1 = g1\n",
    "\n",
    "print(\"Best gammas:\", best_g0, best_g1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ad6f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = preprocess_knn_features(\n",
    "    train, test, y,\n",
    "    [\"latitude\", \"longitude\", \"year\"],\n",
    "    knn_params\n",
    ")\n",
    "\n",
    "model0 = XGBRegressor(device=xgb_device)\n",
    "model1 = XGBRegressor(objective=\"reg:gamma\", device=xgb_device)\n",
    "\n",
    "model0, model1 = fit_two_stage_model(\n",
    "    X_train, y, model0, model1, FOLDS, SEED\n",
    ")\n",
    "\n",
    "print(\"Predicting\")\n",
    "\n",
    "_, lower, upper = build_intervals(\n",
    "    *predict_components(X_test, model0, model1, 1000),\n",
    "    best_g0,\n",
    "    best_g1\n",
    ")\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": test.index,\n",
    "    \"pi_lower\": lower,\n",
    "    \"pi_upper\": upper\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Submission saved!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
